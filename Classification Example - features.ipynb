{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path='data/emotions.csv'):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def get_all_au(df):\n",
    "    return df.loc[:, ' AU01_c':' AU45_c']\n",
    "\n",
    "def get_intensity_au(df):\n",
    "    return df.loc[:, ' AU01_r':' AU45_r']\n",
    "\n",
    "def get_presense_au(df):\n",
    "    return df.loc[:, ' AU01_c':' AU45_c']\n",
    "\n",
    "def get_facial_landmarks(df):\n",
    "    return df.loc[:, ' x_0':' y_67']\n",
    "\n",
    "def get_au_facial_landmarks(df):\n",
    "    X_l = df.loc[:, ' x_0':' y_67']\n",
    "    X_a = df.loc[:, ' AU01_r':' AU45_c']\n",
    "    X = pd.concat([X_l, X_a], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taken from old keras source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different method for classification for maximum emotion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load  and split data for test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataset('data/emotions.csv')\n",
    "X = get_facial_landmarks(df)\n",
    "y = y = df.emotion_label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test = np.asarray(X_train), np.asarray(X_test)\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [5,  7, 9, 16, 17, 22, 44]\n",
    "max_depth = [5, 10, 15, 20, 25, 30, 35]\n",
    "criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [10:59<00:00, 94.19s/it] \n"
     ]
    }
   ],
   "source": [
    "max_f1 = 0.0\n",
    "max_param = \"\"\n",
    "\n",
    "for estimator in tqdm(n_estimators):\n",
    "    for depth in max_depth:\n",
    "        for crit in criterion:\n",
    "            param = str(estimator) + str(depth) + str(crit)\n",
    "            clf = RandomForestClassifier(n_estimators=estimator,\n",
    "                                        max_depth = depth,\n",
    "                                        criterion=crit)                                        \n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = np.argmax(clf.predict(X_test), axis=1)\n",
    "            au_random_forest_f1_test = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "            \n",
    "            if au_random_forest_f1_test > max_f1:\n",
    "                max_f1 = au_random_forest_f1_test\n",
    "                max_param = param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001]\n",
    "losses = ['binary_crossentropy', tf.keras.losses.mean_squared_error]\n",
    "optimizers = [tf.keras.optimizers.Adam, tf.keras.optimizers.RMSprop]\n",
    "input_len = len(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:53<00:00, 133.38s/it]\n"
     ]
    }
   ],
   "source": [
    "max_param = \"\"\n",
    "max_f1 = 0\n",
    "\n",
    "for learning_rate in tqdm(learning_rates):\n",
    "    for loss in losses:\n",
    "         for optimizer in optimizers:\n",
    "                param = str(learning_rate) + str(loss) + str(optimizer)\n",
    "                model = Sequential()\n",
    "                model.add(Dense(input_len, input_dim=input_len, activation='relu'))\n",
    "                model.add(Dense(8, activation='sigmoid'))\n",
    "                opt = optimizer(learning_rate=learning_rate)\n",
    "                model.compile(loss=loss, optimizer=opt, metrics=['accuracy', get_f1])\n",
    "                history = model.fit(X_train, y_train , epochs=50, verbose=0)\n",
    "                y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "                y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "                au_model_f1_test = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "                \n",
    "                if max_f1 < au_model_f1_test:\n",
    "                    max_f1 = au_model_f1_test\n",
    "                    max_param = param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different method for classification for emotion vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load  and split data for test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataset('data/emotions.csv')\n",
    "X = get_facial_landmarks(df)\n",
    "y = df.emotion_label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test = np.asarray(X_train), np.asarray(X_test)\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [5,  7, 9, 16, 17, 22, 44]\n",
    "max_depth = [5, 10, 15, 20, 25, 30, 35]\n",
    "criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [10:30<00:00, 90.07s/it] \n"
     ]
    }
   ],
   "source": [
    "max_similarity = 0\n",
    "max_param = ''\n",
    "\n",
    "for estimator in tqdm(n_estimators):\n",
    "    for depth in max_depth:\n",
    "        for crit in criterion:\n",
    "            param = str(estimator)+str(depth)+str(crit)\n",
    "            clf = RandomForestClassifier(n_estimators=estimator,\n",
    "                                        max_depth = depth,\n",
    "                                        criterion=crit)                                        \n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred =  clf.predict(X_test)\n",
    "            cosine_similarity_arr = cosine_similarity(y_pred, y_test)\n",
    "            counter = 0\n",
    "            for i in range(len(y_pred)):\n",
    "                if cosine_similarity_arr[i][i] >= 0.6:\n",
    "                    counter = counter +1 \n",
    "            tmp = counter / len(y_pred) * 100\n",
    "            if tmp > max_similarity:\n",
    "                max_similarity = tmp\n",
    "                max_param = param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001]\n",
    "losses = ['binary_crossentropy', tf.keras.losses.mean_squared_error]\n",
    "optimizers = [tf.keras.optimizers.Adam, tf.keras.optimizers.RMSprop]\n",
    "input_len = len(X_train[1])\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:45<00:00, 131.38s/it]\n"
     ]
    }
   ],
   "source": [
    "max_param = \"\"\n",
    "max_f1 = 0\n",
    "for learning_rate in tqdm(learning_rates):\n",
    "    for loss in losses:\n",
    "         for optimizer in optimizers:\n",
    "                param = str(learning_rate) + str(loss) + str(optimizer)\n",
    "                model = Sequential()\n",
    "                model.add(Dense(input_len, input_dim=input_len, activation='relu'))\n",
    "                model.add(Dense(8, activation='sigmoid'))\n",
    "                opt = optimizer(learning_rate=learning_rate)\n",
    "                model.compile(loss=loss, optimizer=opt, metrics=['accuracy', get_f1])\n",
    "                history = model.fit(X_train, y_train , epochs=50, verbose=0)\n",
    "                y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "                au_model_f1_test = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                if max_f1 < au_model_f1_test:\n",
    "                    max_f1 = au_model_f1_test\n",
    "                    max_param = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
